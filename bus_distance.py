import streamlit as st
from streamlit_audio_recorder import audio_recorder
import whisper
import tempfile
import os
from pydub import AudioSegment
from gtts import gTTS

# Whisper ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = whisper.load_model("base")

st.title("ğŸ¤ Whisper + gTTS: ë§í•˜ë©´ ì½ì–´ì£¼ëŠ” AI")

# ğŸ™ï¸ 1. ì˜¤ë””ì˜¤ ë…¹ìŒ
audio_bytes = audio_recorder(
    text="ëˆŒëŸ¬ì„œ ë§í•˜ê³  ë‹¤ì‹œ ëˆŒëŸ¬ì„œ ë©ˆì¶”ì„¸ìš”", 
    recording_color="#e74c3c", 
    neutral_color="#2ecc71", 
    icon_name="mic"
)

if audio_bytes:
    # ğŸ”„ 2. ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_wav:
        tmp_wav.write(audio_bytes)
        wav_path = tmp_wav.name

    # ğŸ” WAV â†’ MP3 (WhisperëŠ” mp3ë„ ë¨, gTTSë„ mp3)
    mp3_path = wav_path.replace(".wav", ".mp3")
    AudioSegment.from_wav(wav_path).export(mp3_path, format="mp3")

    # ğŸ” 3. Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
    with st.spinner("ğŸ§  ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
        result = model.transcribe(mp3_path, language="ko")
        text = result["text"]

    st.success("âœ… ì¸ì‹ ì™„ë£Œ!")
    st.markdown(f"**ğŸ“ ì¸ì‹ëœ ë¬¸ì¥:** {text}")

    # ğŸ”Š 4. gTTSë¡œ í…ìŠ¤íŠ¸ â†’ ìŒì„± ìƒì„±
    tts = gTTS(text=text, lang="ko")
    tts_path = os.path.join(tempfile.gettempdir(), "tts.mp3")
    tts.save(tts_path)

    # â–¶ï¸ 5. ìŒì„± ì¬ìƒ
    st.audio(tts_path, format="audio/mp3")

    # ğŸ§¹ 6. ì„ì‹œ íŒŒì¼ ì‚­ì œ
    os.remove(wav_path)
    os.remove(mp3_path)
